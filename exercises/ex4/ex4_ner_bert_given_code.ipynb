{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/konstantinoskalyfommatos/dbs_paper_implementation/blob/main/exercises/ex4/ex4_ner_bert_given_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBK3YDwgVBjN"
      },
      "source": [
        "# Load and prepare the required data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqqgMPaTyVsT",
        "outputId": "9f08e9f1-7954-4de6-8e4f-49fb2cfd0b1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WV5IWPkxmjo"
      },
      "outputs": [],
      "source": [
        "# Choose a supported language, apart from English. Examples: \"de\", \"fr\", \"es\", \"it\".\n",
        "# NOTE: See dataset card for supported languages (https://huggingface.co/datasets/unimelb-nlp/wikiann)\n",
        "chosen_language_code = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggqfgV_nO5Qj"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "\n",
        "# NOTE: If the maximum sequence length exceeds the model's maximum\n",
        "# sequence length, you need to make adjustments (for example, when\n",
        "# choosing 'en')\n",
        "test_set = datasets.load_dataset(\"unimelb-nlp/wikiann\", chosen_language_code, split=\"test[:2000]\")\n",
        "train_set1000 = ...\n",
        "train_set3000 = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNYxEU3YO5Ql"
      },
      "source": [
        "**NOTE: Make sure that there are indeed as many data points in the above sets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMFy3wCLO5Qm"
      },
      "outputs": [],
      "source": [
        "print(train_set1000)\n",
        "print(train_set3000)\n",
        "print(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N0wMdjnvO5Qn"
      },
      "outputs": [],
      "source": [
        "ner_tags = {\n",
        "    \"O\": 0,\n",
        "    \"B-PER\": 1,\n",
        "    \"I-PER\": 2,\n",
        "    \"B-ORG\": 3,\n",
        "    \"I-ORG\": 4,\n",
        "    \"B-LOC\": 5,\n",
        "    \"I-LOC\": 6\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ArOWU99T58D"
      },
      "source": [
        "**TODO: Inspect and Describe the Data, including Average and Maximum Input length (in tokens)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfyYXRLoU6mV"
      },
      "source": [
        "üìù‚ùìWhy do you need to be aware of the longest input length within your dataset? Which parameter of the model dictates this?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-1XQS_M2WO2"
      },
      "outputs": [],
      "source": [
        "# TODO: Adjust by actually finding the maximum sequence length\n",
        "max_sequence_length = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idpa54l4O5Qv"
      },
      "outputs": [],
      "source": [
        "print(max_sequence_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KxkH5vBO5Qw"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "# TODO: Load the tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2qFayooO5Qx"
      },
      "source": [
        "üìù‚ùìThe dataset is split into words, and the assigned labels are for words. How should we deal with labels **after** tokenization? NOTE: Each word may be split into one or multiple tokens by the tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvc66dR9x6Fe"
      },
      "outputs": [],
      "source": [
        "# TODO: Implement this function\n",
        "def encode_and_align_labels(dataset, tokenizer, max_sequence_length):\n",
        "    \"\"\"Tokenizes the input tokens and aligns the word-level NER labels with the tokenized output.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0zufGtNw6yk"
      },
      "outputs": [],
      "source": [
        "# TODO: Encode the two training sets and the test set by applying the function above\n",
        "encoded_test_set = ...\n",
        "encoded_train_set1000 = ...\n",
        "encoded_train_set3000 = ...\n",
        "\n",
        "\n",
        "\n",
        "# Set format for PyTorch\n",
        "encoded_test_set.set_format(\n",
        "    type=\"torch\",\n",
        "    columns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
        ")\n",
        "encoded_train_set1000.set_format(\n",
        "\ttype=\"torch\",\n",
        "\tcolumns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
        ")\n",
        "encoded_train_set3000.set_format(\n",
        "\ttype=\"torch\",\n",
        "\tcolumns=[\"input_ids\", \"attention_mask\", \"labels\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oykr25qgnBOg"
      },
      "outputs": [],
      "source": [
        "# Check out how the training sets are encoded\n",
        "for key, val in encoded_train_set1000[0].items():\n",
        "    print(f'{key}: {val.size()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEJXYvbOa-E4"
      },
      "source": [
        "Example of how your output could look like.\n",
        "\n",
        "input_ids: torch.Size([???])\n",
        "\n",
        "token_type_ids: torch.Size([???])\n",
        "\n",
        "attention_mask: torch.Size([???])\n",
        "\n",
        "labels: torch.Size([???])\n",
        "\n",
        "üìù‚ùìWhat value should replace the three question marks in your print? Should this be the sample for all samples? Why/Why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnWH-MaKO5Q1"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdIPhpLiO5Q1"
      },
      "source": [
        "## Training Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sy2LxB_2O5Q2"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForTokenClassification, Trainer, TrainingArguments\n",
        "import os\n",
        "os.environ[\"WANDB_MODE\"] = \"disabled\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSpxJMtkO5Q3"
      },
      "source": [
        "**TODO: Complete the following, reusable functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKhJH6wQO5Q4"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(preds):\n",
        "    \"\"\"\n",
        "    Compute macro and micro F1 scores from PredictionOutput\n",
        "\n",
        "    Args:\n",
        "        preds: transformers.trainer_utils.PredictionOutput\n",
        "\n",
        "    Returns:\n",
        "        dict with macro_f1 and micro_f1 scores\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePcLuf4QO5Q4"
      },
      "outputs": [],
      "source": [
        "def freeze_weights(model):\n",
        "    \"\"\"Freeze the weights for a given model.\n",
        "\n",
        "    Args:\n",
        "        model: transformers.PreTrainedModel\n",
        "\n",
        "    Returns:\n",
        "\t\t\tmodel: transformers.PreTrainedModel\n",
        "    \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cevovk8ZO5Q5"
      },
      "source": [
        "## Variation 1: 1000 sentences, no frozen weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru--p5NZO5Q6"
      },
      "source": [
        "**TODO: Initialise your model and set up your training arguments**\n",
        "\n",
        "üìù‚ùìWhen initializing the BertForTokenClassification-class with BERT-base you should get a warning message. Explain why you get this message.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JD72g8GC2Rwx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_DBflx1wzRa"
      },
      "source": [
        "**TODO: Train your Model ‚ö° GPU 2-3 mins**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3XEgVHrxJTq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bt86VaDIiMWd"
      },
      "source": [
        "**TODO: Compute Metrics/Performance of your model.**\n",
        "\n",
        "üìù‚ùì Is there a challenge when evaluating the predictions of your model? Why is this challenge present and how do you plan to deal with it?\n",
        "\n",
        "Hint: Look at the lengths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ryi-Vnrw7NJ"
      },
      "source": [
        "To avoid rerunning, please also print the metrics of each model that completed training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nE3HeKW4TFl"
      },
      "outputs": [],
      "source": [
        "# print(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AKh4cXm7F8R"
      },
      "source": [
        "## Variant 2: 3000 sentences, no frozen weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHmo4lCp2Bj7"
      },
      "outputs": [],
      "source": [
        "# Repeat after each run to save VRAM\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsU1E0_p7ITW"
      },
      "source": [
        "## Variant 3: 1000 sentences, frozen weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTXRQCgz7Vcu"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6wE6mAm7y7m"
      },
      "source": [
        "## Variant 4: 3000 sentences, frozen weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RxkAuigt7y7n"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iTcwgmtO5Q_"
      },
      "source": [
        "# Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2LyNOP6oVsz"
      },
      "source": [
        "üìù‚ùì Template:\n",
        "\n",
        "Summary of Performance of the four Model Variants\n",
        "\n",
        "1. Whole Model finetuning, 1000 samples:\n",
        "2. Whole Model finetuning, 3000 samples:\n",
        "3. Frozen Backbone, 1000 samples:\n",
        "4. Frozen Backbone 3000 samples:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPi_aox2O5RA"
      },
      "source": [
        "üìù‚ùì When we freeze the transformer backbone weights, which weights are being tuned during fine-tuning?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uR2j40qivASb"
      },
      "source": [
        "üìù‚ùì Are there differences between f1-micro and f1-macro score? If so, why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqyOEWsr-J4s"
      },
      "source": [
        "üìù‚ùì Is it better to freeze or not to freeze the transformer backbone weights? Hypothesize why"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBCHlRNgxPTn"
      },
      "source": [
        "\n",
        "\n",
        "üìù‚ùì Write your lab report here addressing all questions in the notebook"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "ML4NLP1-2025-Tutorial-Notebooks",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}